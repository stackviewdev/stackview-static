
[{
            "title": "Quick Guide: Configuring Git on Your Local System - StackView",
            "excerpt": "Learn about how to install & configure git on your operating system with easy to follow step by step guide.",
            "category": "Version Control",
            "date": "2025-10-13T00:00:00.000Z",
            "url": "/blog/configure-git-on-local-system/",
            "content": "Before going to run any git operations we have to do some configurations on your local system. It is used to set configuration values on global or local project levels. üëâ Global: For all projects on your local system. üëâ Local: For all projects on a directory So let‚Äôs do it. Open the terminal and run the following commands. If you want to configure git globally follow below instuction: #Set the User name git config --global user.name \"name\" #Set the email-ID git config --global user.email &quot;Git-Hub email-Id&quot; #To list all the configurations git config --list Copy Code If you want to configure git locally follow below instuction: # Set the User name git config --local user.name \"\" #Set the email-ID git config --local user.email &quot;&quot; #To list all the configurations git config --list Copy Code We are now ready to use Git. Hope this was helpful ‚úåÔ∏è Recommended for you üëâ How to Install Git on Your Local System Step-by-Step Guide for Beginners",
            "keywords": "Python, CSV, Pandas, git, version control"
        }
        ,{
            "title": "How to create an Excel file with Python using xlwt - StackView",
            "excerpt": "Python's XLWT library allows you to write Excel files. In addition to text and numbers, formulas can also be entered into multiple worksheets. Other features include styling text, managing column size, and more.",
            "category": "Python",
            "date": "2025-10-13T00:00:00.000Z",
            "url": "/blog/create-excel-with-python/",
            "content": "Python's XLWT library allows you to write Excel files. In addition to text and numbers, formulas can also be entered into multiple worksheets. Other features include styling text, managing column size, and more. How to install xlwt librabry Install xlwt with the below command. pip install xlwt In order to test our code after installation, we need to create a dummy data set. data = [ { \"name\":\"Testuser1\", \"age\":20, \"country\":\"India\" }, { \"name\":\"Testuser2\", \"age\":20, \"country\":\"Canada\" }, { \"name\":\"Testuser2\", \"age\":29, \"country\":\"USA\" }, ] Copy Code Now we have the data to create excel file. How to create Excel with Python using xlwt Please follow the below given code # Import workbook to write data from xlwt from xlwt import Workbook #Create an object of the workbook excel = Workbook() #Add sheet in workbook sheet = excel.add_sheet(&quot;Test Data&quot;) for index, value in enumerate(data): sheet.write(index, 0, value[&quot;name&quot;]) sheet.write(index, 1, value[&quot;age&quot;]) sheet.write(index, 2, value[&quot;country&quot;]) #Now save the excel save_location = &quot;path/to/your/working/directory/result.xls&quot; excel.save(save_location) Copy Code Thanks for visiting StackView",
            "keywords": "Python, CSV, Pandas, reader"
        }
        ,{
            "title": "Exploratory Data Analysis: Iris Flower Dataset in-depth - StackView",
            "excerpt": "EDA is a process or approach to finding out the most useful features from the dataset according to your problem which helps you to choose the correct and efficient algorithm for your solution.",
            "category": "Data Analysis",
            "date": "2025-10-13T00:00:00.000Z",
            "url": "/blog/exploratory-data-analysis/",
            "content": "What is Exploratory Data Analysis? In simple words: EDA is a process or approach to finding out the most useful features from a datasetaccording to your problem which helps you to choose the correct and efficient algorithm for your solution. Why is Exploratory Data Analysis Important? As we know there are some prerequisites for every project and we can say that EDA is a prerequisite process for any data science or machine learning project. If you are in a hurry and skip EDA then you may face some outliers and too many missing values and, therefore, some bad outcomes for the project: Wrong model Right model on wrong data Selection of wrong features for model building How to do Exploratory Data Analysis? We can do EDA with programming languages and data visualization tools. The most popular programming languages are: Python R The most popular data visualization tools are: Tableau Power BI Infogram Plotly Let‚Äôs dive into the Iris Flower dataset: To download the Iris flower dataset: (https://www.kaggle.com/arshid/iris-flower-dataset) Key points about the dataset: 1. The shape of data is (150 * 4) which means rows are 150 and columns are 4 and these columns are named sepal length, sepal width, petal length, and petal width. 2. There is a species column that tells us about the label of the flower according to the given data there are three categories of flower named Iris setosa, Iris Verginica, and Iris versicolor. 3. Dataset is having 33% of each category's data. Now we are going to do EDA with the programming language named Python. Python has a massive amount of libraries to apply the various types of operations on data to find out the best results. Import some important Libraries. # Import libraries import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns Copy Code The next step is to load data. if data is in CSV format then use these lines of code to load data into a variable named Data. iris = pd.read_csv(\"iris.csv\") Copy Code To observe the top 5 rows of the data using the head function which gives the first 5 rows of the data. iris.head() Copy Code OUTPUT: To check the last five rows of the data we can use data.tail() and for modifying the number of rows we can use data.head(3) or data.tail(3). To check the dimensionality of the dataset iris.shape() Copy Code OUTPUT: The shape of the data is (150, 4) To check the column names or feature names iris.columns Copy Code OUTPUT: Index([‚Äòsepal_length‚Äô, ‚Äòsepal_width‚Äô, ‚Äòpetal_length‚Äô, ‚Äòpetal_width‚Äô, ‚Äòspecies‚Äô], dtype = ‚Äòobject‚Äô ) To check how many points of each class iris['species'].values_count() Copy Code OUTPUT: versicolor: 50, setosa: 50, virginica: 50 As we can observe all three classes are equally distributed in terms of the number of counts of each class. Here we can understand a very interesting concept called balanced and imbalanced dataset. Balanced Dataset Let's say we have 10000 rows and it has 2 classes. and class A has 4000 points(point = row) and class B has 6000 points this dataset is a balanced dataset. (Examples: (5000, 5000), (5500, 4500), (6000, 4000)). Imbalanced Dataset Let's say we have 10000 rows and it has 2 classes. and class A has 2000 points and class B has 8000 points and this dataset is the imbalanced dataset. (Examples: (1000, 9000), (1500, 8500), (2000, 8000)) We aim to get a balanced dataset our machine learning algorithms could be biased and inaccurate if data is imbalanced. there are various techniques to handle the case of an imbalanced dataset you can go to this link From the above explanation, you may get some idea about the balanced and imbalanced datasets. Some Basic information about the dataset iris.info() Copy Code Observation Now we can say that there is not any data point missing in any feature. And all first 4 features are of float64 type which is used in numpy and pandas. And indexes are from 0 to 149 for 150 entries. And the last column is of type object which is used for the class labels. The memory used by this data frame is around 6 KB. Some Visual views of data # First plot plt.plot(iris[\"species\"]) plt.xlabel(\"No. of data points\") plt.show() Second plot plt.hist(iris[&quot;species&quot;],color=&quot;green&quot;) plt.show() Copy Code Here we see visually by plotting a graph by no. of data points of each class label. To observe more about the data we can see a basic description of the data iris.describe() Copy Code Observation By describing the dataset we can find out the overall mean, standard deviation, minimum and maximum values in each feature, 25, 50, 75 percentile of data distribution. And many more things in another dataset. We can‚Äôt find any useful information in this dataset that tells us about a very useful feature that helps classify all three iris, and flower classes. To do that we can apply some other techniques to find out important features such as plots of various types. Scatter plot A scatter plot is a set of points plotted on horizontal and vertical axes. Scatter plots are important in statistics because they can show the extent of correlation, if any, between the values of observed quantities or phenomena (called variables). If no correlation exists between the variables, the points appear randomly scattered on the coordinate plane. If a large correlation exists, the points concentrate near a straight line. This has come under bivariate analysis. Observation Wow! Here we can see that black color data points(setosa) are totally separate from the other two class data points by a straight line when we plot a scatter plot with the help of sepal length and sepal width. But the separation of Versicolor from Virginica is much harder because they are considered overlaps. To solve this problem we have to observe many other plots. Here we have a scatter plot with only two features but we have to observe all pairs of the features (4c2 = 6) combinations to see all features in 2D space which is not a good practice and effective by doing one by one. So we have good news we can do it by a single line of code with a pair plot. Pair plot By default, this function will create a grid of Axes such that each variable in data will be shared in the y-axis across a single row and in the x-axis across a single column. The diagonal Axes are treated differently, drawing a plot to show the univariate distribution of the data for the variable in that column. Disadvantage: we can not visualize higher dimension data like 10D data it is perfect for up to 6D data. And work only in 2D data. If you want to observe 3D scatter plot go to this link. This has come under bivariate data analysis. sb.set_style('whitegrid') sb.pairplot(iris,hue='species',size=3) plt.show() Copy Code Observation We can observe from the pair plot that petal length and petal width are the most useful features to classify iris flower to there respective class. Verginica and Versicolor are a little bit overlapped but they are almost linearly separable. There are many other ways to know about the dataset if the above method is not work in any case. Now we are going to study PDF, CDF, and HISTOGRAM. Why do we need a histogram? iris_setosa = iris.loc[iris['species']=='setosa'] iris_versicolor = iris.loc[iris['species']=='versicolor'] iris_virginica = iris.loc[iris['species']=='virginica'] plt.plot(iris_setosa['petal_length'],np.zeros_like(iris_setosa['petal_length'],),'o',label='setosa') plt.plot(iris_virginica['petal_length'],np.zeros_like(iris_virginica['petal_length'],),'o',label='virginica') plt.plot(iris_versicolor['petal_length'],np.zeros_like(iris_versicolor['petal_length'],),'o',label='versicolor') plt.xlabel(&quot;petal_length&quot;) plt.grid() plt.legend() plt.show() Copy Code Observation The disadvantage of this 1D scatter plot is a lot of overlap between Versicolor and Verginica and we can not say anything about it. To overcome this problem we need a histogram. Histogram and Density Curve on the same plot If you wish to have both the histogram and densities in the same plot, the seaborn package (imported as sns) allows you to do that via the distplot(). Since Seaborn is built on top of matplotlib, you can use the sns and plt one after the other. This has come under univariate data analysis. sb.FacetGrid(iris,hue=\"species\",size=5).map(sb.distplot,'petal_length').add_legend() plt.show() Copy Code Observation Its X-axis tells us all setosa flowers are having a petal length between 1 and 1.8. And Versicolor has petal lengths between 3 and 5.2 and Virginica have petal length between 4.5 and 6.9. Its Y-axis tells us the count of the flower at this x value. or how often they come at this value. And Setosa is fully separated from the other two classes but Versicolor and Virginica are not fully separated they have some overlap of some data points. At x = 5 there is a high probability to get Virginica rather than Versicolor because the height of the Virginica histogram if larger than Versicolor. And this smooth curve is called PDF (Probability Density Function). it is a smooth histogram. PDF(Probability Density Function) The PDF is the density of probability rather than the probability mass. The concept is very similar to mass density in physics. OR The probability density function (PDF) is a statistical expression that defines probability distribution as a continuous random variable as opposed to a discrete random variable. When the PDF is graphically portrayed, the area under the curve will indicate the interval in which the variable will fall. The total area in this interval of the graph equals the probability of a continuous random variable occurring. For other features sb.FacetGrid(iris,hue=\"species\",size=5).map(sb.distplot, 'petal_width').add_legend() plt.show() Copy Code sb.FacetGrid(iris,hue=\"species\",size=5).map(sb.distplot, 'sepal_length').add_legend() plt.show() Copy Code sb.FacetGrid(iris,hue=\"species\",size=5).map(sb.distplot, 'sepal_width').add_legend() plt.show() Copy Code Observation Petal length will do a great job to classify all classes of flowers but we can say that petal length is slightly better than the petal width because petal width is also doing a better job. sepal length and sepal width are not good features to classify iris flowers petal length &gt; petal width &gt;&gt;&gt; sepal length &gt;&gt;&gt;sepal width. CDF (Cumulative distribution function) In probability theory and statistics, the cumulative distribution function (CDF) of a real-valued random variable X, or just distribution function of X, evaluated at x, is the probability that X will take a value less than or equal to x. To plot a CDF and PDF counts,bin_edges=np.histogram(iris_setosa['petal_length'],bins=10,density=True) pdf= counts/(sum(counts)) print(pdf) print(bin_edges) cdf=np.cumsum(pdf) plt.plot(bin_edges[1:],pdf,label='pdf') plt.plot(bin_edges[1:],cdf,label='cdf') plt.legend() plt.show() Copy Code This is only for the setosa class petal length. Observation Let‚Äôs take petal length is equals to 1.5 and then observe it by CDF and PDF. Now we can say that 61% of setosa flowers having petal length is less than 1.5 or in another way we can say between 1.4 and 1.5 petal lengths we have 28% setosa flowers. To plot PDF and CDF for all class counts,bin_edges=np.histogram(iris_setosa['petal_length'],bins=10,density=True) pdf= counts/(sum(counts)) print(pdf) print(bin_edges) to compute cdf cdf=np.cumsum(pdf) plt.plot(bin_edges[1:],pdf,label='pdf') plt.plot(bin_edges[1:],cdf,label='cdf') counts,bin_edges=np.histogram(iris_virginica['petal_length'],bins=10,density=True) pdf= counts/(sum(counts)) print(pdf) print(bin_edges) to compute cdf cdf=np.cumsum(pdf) plt.plot(bin_edges[1:],pdf,label='pdf') plt.plot(bin_edges[1:],cdf,label='cdf') counts,bin_edges=np.histogram(iris_versicolor['petal_length'],bins=10,density=True) pdf= counts/(sum(counts)) print(pdf) print(bin_edges) to compute cdf cdf=np.cumsum(pdf) plt.plot(bin_edges[1:],pdf,label='pdf') plt.plot(bin_edges[1:],cdf,label='cdf') plt.legend() plt.show() Copy Code Mean, variance, and standard deviation To get more ideas about data. # Means of the petal length print(\"Means\") print(\"setosa\",np.mean(iris_setosa[\"petal_length\"])) print(\"versicolor\",np.mean(iris_versicolor[\"petal_length\"])) print(\"virginica\",np.mean(iris_virginica[\"petal_length\"])) standard-daviation print(&quot;standard-daviation&quot;) print(&quot;setosa :&quot;,np.std(iris_setosa[&quot;petal_length&quot;])) print(&quot;versicolor :&quot;,np.std(iris_versicolor[&quot;petal_length&quot;])) print(&quot;virginica :&quot;,np.std(iris_virginica[&quot;petal_length&quot;])) median print(&quot;median&quot;) print(&quot;setosa :&quot;,np.median(iris_setosa[&quot;petal_length&quot;])) print(&quot;versicolor :&quot;,np.median (iris_versicolor[&quot;petal_length&quot;])) print(&quot;virginica :&quot;,np.median (iris_virginica[&quot;petal_length&quot;])) Copy Code here if we talk about variance then this is a spread of how far our elements are spread (width of histogram‚Äôs graph) We can observe various things by only one or two plots and the names of those plots are BOX plot and VIOLIN plot. but to understand these plots we have to understand the basic concept of percentile. Percentile x percentile tells us what % of data points are smaller than this value and what % of elements are greater than this value. The 50th percentile is the median. 25th,50th,75th, and 100th percentiles are called quantiles. 25th is a first, 50th is a second, 75th is a third, and 100th is the fourth quantile. print(\"90th percentile\") print(\"setosa:\",np.percentile(iris_setosa[\"petal_length\"],90)) print(\"versicolor:\",np.percentile(iris_versicolor[\"petal_length\"],90)) print(\"virginica:\",np.percentile(iris_virginica[\"petal_length\"],90)) Copy Code What is a box and whisker plot? A box and whisker plot ‚Äî also called a box plot ‚Äî displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum. In a box plot, we draw a box from the first quartile to the third quartile. A vertical line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum. sb.boxplot(x='species',y='petal_length',data=iris) plt.grid() plt.show() Copy Code What is a violin plot? A violin plot is a method of plotting numeric data. It is similar to a box plot, with the addition of a rotated kernel density plot on each side. Violin plots are similar to box plots, except that they also show the probability density of the data at different values, usually smoothed by a kernel density estimator. b.violinplot(x='species',y='petal_length',data=iris,size=8) plt.grid() plt.show() Copy Code A 3D plot of the iris flower dataset import plotly.express as px fig = px.scatter_3d(Data, x='sepal_length', y='sepal_width', z='petal_width', color='species') fig.show() Copy Code Thanks for visiting StackView",
            "keywords": "Python, CSV, Pandas, data analysis"
        }
        ,{
            "title": "How to export DataFrame to CSV using pandas - StackView",
            "excerpt": "Explore: How to save/export DataFrame to CSV using pandas with python programming language. It will save your CSV file to your given location very easily.",
            "category": "Python",
            "date": "2025-10-13T00:00:00.000Z",
            "url": "/blog/export-dataframe-to-csv-with-pandas/",
            "content": "It is well known that Pandas is a popular library for manipulating and analyzing data. Additionally, it is widely used in Python and is open-source. Most of the time, we find that the data is enormous when we begin analyzing it. Once we analyzed the data, we discovered some columns were not necessary or sometimes we needed to preprocess it. It could be anything. Once the data has been refined, we want to save it locally so we can use it in the future without having to repeat the entire process. Pandas have a method .to_csv() for storing data into CSV files which are exported and saved locally. The following code demonstrates how it works. import pandas as pd #Create a simple data frame data = { 'Name': ['John', 'Mary', 'James', 'Linda', 'Robert'], 'Age': [28, 23, 31, 19, 36], 'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'] } df = pd.DataFrame(data) #Write the dataframe object into a CSV file df.to_csv(&quot;/path/to/your/csvfile.csv&quot;, index=False, sep=',', encoding='utf-8') print(&quot;File Created Successfully&quot;) Copy Code Parameters used in .to_csv() functions. üëâ The first parameter specifies the name of the CSV file (in my case, it's &quot;csvfile.csv&quot;). You would need to specify the full path if the file is not in the same directory as your script. üëâ index=False means that we will not write row names (index). If you want to include the index, you can set index=True or remove this parameter because its default value is True. üëâ sep=',' defines the delimiter to use. In this case, we use a comma. üëâ encoding='utf-8' specifies the encoding to be used for the file. This is optional, and if not specified, it will default to 'utf-8'. This script will create the csvfile.csv file in the same directory after it is run. You can create the file in another directory by replacing csvfile.csv with the full path. An example would be: import pandas as pd #Create a simple data frame data = { 'Name': ['John', 'Mary', 'James', 'Linda', 'Robert'], 'Age': [28, 23, 31, 19, 36], 'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'] } df = pd.DataFrame(data) #Write the data frame object into a CSV file df.to_csv(&quot;/path/to/your/csvfile.csv&quot;, index=False, sep=',', encoding='utf-8') print(&quot;File Created Successfully&quot;) Copy Code Make sure you replace /path/to/your/csvfile.csv with your actual CSV file path. Hopefully üôå this blog helps you. Frequently Asked Questions(FAQs) In the CSV file, how can I make sure that special characters are exported properly? DataFrames with special characters can easily be exported to CSV files using to_csv()'s encoding parameter. Pandas will correctly handle Unicode characters in your data if you specify encoding='utf-8'. You can use DataFrame.to_csv('my_file.csv', encoding='utf-8') to manage these characters properly. Is there a way to include or exclude the DataFrame's index when exporting to CSV? CSV files generated by the to_csv() function include the DataFrame's index by default. Pass index=False as an argument to the function if you want to exclude it. An example would be DataFrame.to_csv(filename, index=False). As an alternative, you can use this argument or set index=True to include the index. What is the function name in pandas to export a DataFrame to a CSV file? A DataFrame can be exported to a CSV file using the to_csv() function in pandas. DataFrame.to_csv(filename) is the basic syntax, where 'filename' is the name of the CSV file to generate.",
            "keywords": "Python, CSV, Pandas, dataframe"
        }
        ,{
            "title": "How to read CSV files with or without Pandas - StackView",
            "excerpt": "CSV Means Comma Separated Values. CSV is a simple file used to store data as a spreadsheet or database. And we can read it with or without Pandas.",
            "category": "Python",
            "date": "2025-10-13T00:00:00.000Z",
            "url": "/blog/how-to-read-csv/",
            "content": "Full form of CSV: Comma Separated Values CSV files contain lists of data separated by commas in plain text format. Basically we use CSV files to exchange and transfer data from one destination to another. And we can read it with or without Pandas. To download dataset please visit Here How to read CSV file with Pandas #Import Pandas library import pandas as pd #Import the Dataset file. Pandas has read_csv method that help to load .csv file file_path = &quot;iris.csv&quot; data = pd.read_csv(file_path) #Let's see first five datapoints data.head(5) #Output: You will get the first 5 rows of the Dataset #['sepal.length', 'sepal.width', 'petal.length', 'petal.width', 'variety'] #['5.1', '3.5', '1.4', '.2', 'Setosa'] #['4.9', '3', '1.4', '.2', 'Setosa'] #['4.7', '3.2', '1.3', '.2', 'Setosa'] #['4.6', '3.1', '1.5', '.2', 'Setosa'] #['5', '3.6', '1.4', '.2', 'Setosa'] Copy Code How to read CSV file without using the Pandas library CSV Python's built-in library can be used to read csv files without using pandas. Here we are using the reader() function to read the data from the file. # Import reader module from csv Library from csv import reader #read the CSV file def load_csv(filename): # Open file in read mode file = open(filename,&quot;r&quot;) # Reading file lines = reader(file) # Converting into a list data = list(lines) return data if name == &quot;main&quot;: # Path of the dataset file_path = &quot;iris.csv&quot; data = load_csv(file_path) # Let's print the first 5 datapoints for row in data[:6]: print(row, end = &quot;\\n&quot;) #Output: You will get the first 5 rows of the Dataset as given below. #['sepal.length', 'sepal.width', 'petal.length', 'petal.width', 'variety'] #['5.1', '3.5', '1.4', '.2', 'Setosa'] #['4.9', '3', '1.4', '.2', 'Setosa'] #['4.7', '3.2', '1.3', '.2', 'Setosa'] #['4.6', '3.1', '1.5', '.2', 'Setosa'] #['5', '3.6', '1.4', '.2', 'Setosa'] Copy Code Although load_csv() is a helpful function, it has some limitations. While reading files, it doesn't handle empty spaces/row. We can solve this problem by using a list. To solve this problem you can use the below code snippets. Let see #Load the CSV file def load_csv(filename): data = list() # Open file in read mode file = open(filename,&quot;r&quot;) # Reading file lines = reader(file) csv_reader = reader(file) for row in csv_reader: if not row: continue data.append(row) return data if name == &quot;main&quot;: # Path of the dataset filename = &quot;iris.csv&quot; data = load_csv(filename) # Let's print the first 5 datapoints for row in data[:6]: print(row, end = &quot;\\n&quot;) #['sepal.length', 'sepal.width', 'petal.length', 'petal.width', 'variety'] #['5.1', '3.5', '1.4', '.2', 'Setosa'] #['4.9', '3', '1.4', '.2', 'Setosa'] #['4.7', '3.2', '1.3', '.2', 'Setosa'] #['4.6', '3.1', '1.5', '.2', 'Setosa'] #['5', '3.6', '1.4', '.2', 'Setosa'] Copy Code Thanks üôå for visiting StackView.",
            "keywords": "Python, CSV, Pandas, reader"
        }
        ,{
            "title": "How to read Excel file in Python without using Pandas - StackView",
            "excerpt": "Learn how to read Excel file in Python programming language without using Pandas library. We can read Excel file with other python libraries like openpyxl and xlrd. Boost your Python skills by learning these new techniques.",
            "category": "Python",
            "date": "2025-10-13T00:00:00.000Z",
            "url": "/blog/how-to-read-excel-in-python-without-pandas/",
            "content": "Reading of an Excel files with extensions(.xls, .xlsx) can be done without using Pandas in Python programming. Instead of using Pandas we can use other alternative libraries like xlrd, openpyxl. In this article we will see how we can read Excel file in Python by using xlrd library. Related Article: How to create Excel file with xlwt How to Install xlrd librabry First of all we have to install xlrd in our local environment. And xlrd can be installed using pip (Python package manager). Use the given command to install it. pip install xlrd Read Excel with xlrd Method open_workbook will opens up the given Excel file so that we can read that file. import xlrd #Open the Excel file workbook = xlrd.open_workbook('test.xls') # Replace 'your_excel_file.xls' with your file path #Select the sheet you want to read (by index) sheet = workbook.sheet_by_index(0) #Iterate through rows and columns to access data for row in range(sheet.nrows): for col in range(sheet.ncols): cell_value = sheet.cell_value(row, col) print(cell_value, end='\\t') print() # Move to the next row #Close the Excel file (not required for reading, but good practice) workbook.release_resources() Copy Code To read a perticular sheet in the Whole Excel file we can select sheets by sheet_by_index method. Note: nrows and ncols will measure and tell how many rows and coulmns we have in a sheet. Hopefully you are able to read Excel files with xlrd. FAQs Can I use these libraries to write data to Excel files as well? No, Both openpyxl and xlrd are primarily build &amp; used to only read. To write data to Excel files, you may need to explore other libraries or techniques. What are the advantages of using libraries like openpyxl or xlrd over Pandas? Libraries like openpyxl and xlrd are lighter, more efficient, and better suited for specific Excel file reading tasks.",
            "keywords": "Python, CSV, Pandas, reader"
        }
        ,{
            "title": "How to Install Git on Your Local System Step-by-Step Guide for Beginners - StackView",
            "excerpt": "Learn about how to install git on your operating system with easy to follow step by step guide. Complete guide for Linux, MacOs, and Window installation.",
            "category": "Version Control",
            "date": "2025-10-13T00:00:00.000Z",
            "url": "/blog/install-git-on-local-system/",
            "content": "Install Git according to the operating system you are using. Install Git on Ubuntu(Linux) Step 1: Update the system packages sudo apt-get update Step 2: Install git sudo apt-get install git Step 3: Check the git version git --version That's all you need to do to install Git on your Ubuntu operating system. Install Git on MacOs Step 1: Install the git brew install git Step 2: Check the Git version git --version That is also done! How quick is that. Install Git on Windows Open the browser 1. Download the latest version of the Git Windows Installer. Link: https://git-for-windows.github.io/ 2. After successfully downloading the installer you will see the installer screen(or just click on the downloaded file) and use the default setting. Follow the next and finish option. 3. After installing Git via the installer. You just need to go start menu and open ‚ÄúGit Bash‚Äù Thats all from our side üôå now it's your turn install and enjoy the git.",
            "keywords": "Python, CSV, Pandas, git, version control"
        }
        ,{
            "title": "Statistics: Mean, Median, and Mode with examples - StackView",
            "excerpt": "The mean is the sum of all values of a dataset divided by total numbers. The mode is the most frequent number in a dataset. The median is the middle of the set of numbers when it is in sorted order.",
            "category": "Statistics",
            "date": "2025-10-13T00:00:00.000Z",
            "url": "/blog/mean-median-mode/",
            "content": "Do you ever think about how many percent of people own a larger portion of the wealth? Let‚Äôs take an example of India, According to Oxfam 2017 report, The top 10% of the Indian population holds 77% of the total national wealth. 73% of the wealth generated in 2017 went to the richest 1%, while 67 million Indians who comprise the poorest half of the population saw only a 1% increase in their wealth. So as you can see, there is an unequal distribution of wealth in India. It is also much the same in other parts of the world. We often think that if wealth is equally divided then how good it will be. Suppose today is your lucky day, your wish is granted and all the people have decided to distribute wealth equally among themself. Here the question arises. 1. How will you distribute wealth equally? 2. How the government calculates the average salary for a country? 3. Which salary range has the maximum number of people? Here maths comes to solve your problem, we all have heard the three most popular words of maths MEAN, MEDIAN, and MODE. Now we have to find out when and where these are going to help us. Let‚Äôs understand it with the help of an example. country X has 10 people and we have their wealth data as given below. Now we come to our first question. How will you distribute wealth equally? First, we have to calculate what is the total wealth. So for that, we will sum up the wealth. Total wealth = 7 + 3 + 20 + 12 + 1 + 9 + 5 + 17 + 22 + 8 = 104 Million Now we calculate how much any individual will get = Total Wealth / Total no. of people = 104 / 10 = 10.4 Million If we distribute wealth equally among all the people then each one will get 10.4 million. What we calculate above, In a maths language that is called MEAN. MEAN MEAN: Mean is the sum of all the items divided by the total number of items. It is also called Average. It‚Äôs time for the second question. How the government calculates the average salary for a country? First, we will short(arrange all salaries in increasing or decreasing order) the data. Now we will find out the middle point in the data. But items are even so we will take the middle two items. Here person J and F. Whose wealth are 8 and 9 million respectively. We will take the mean of J and F wealth the find out the middle value. = 8+9 / 2 = 8.5 Million The middle value is 8.5 Million. This is the answer to our second question. This whole process is also called MEDIAN. MEDIAN MEDIAN: The number in the middle in sorted data is called MEDIAN. If data has even items then the Median will be the mean of those two middle values. If data has an odd no. of items. If data has even no. of items. It‚Äôs time for our last question. Which salary range has the maximum number of people? First, we will decide the range and count the people in that range. Most of the people have salaries in the range of 5 million to 10 million. It is called MODE in Maths. MODE MODE: Which item has the highest frequency is called MODE. According to the number line,2 is the mode. Thanks for visiting StackView.",
            "keywords": "python, CSV, pandas, statistics, data analysis"
        }
        ,{
            "title": "How to change timezone in Django projects",
            "excerpt": "Learn, How we can change the timezone of our Django project then the project will refer to that time to give you a time stamp on that timezone.",
            "category": "Django",
            "date": "2024-05-19T00:00:00.000Z",
            "url": "/answer/change-timezone-in-django-project/",
            "content": "In this answer - We will take a closer look at how to set or change your desired time zone in your existing Django project. Here is an example of a newly created Django project directory structure in this case our project name is MyLedger |‚îÄ‚îÄ MyLedger ‚îú‚îÄ‚îÄ init.py ‚îú‚îÄ‚îÄ asgi.py ‚îú‚îÄ‚îÄ settings.py ‚îú‚îÄ‚îÄ urls.py ‚îî‚îÄ‚îÄ wsgi.py |‚îÄ‚îÄ manage.py Steps to set the timezone in the Django project PATH: MyLedger -&gt; settings.py -&gt; search &quot;TIME_ZONE&quot; -&gt; change Go to your project directory in this case we have the MyLedger directory. Go to the settings.py file. Search for TIME_ZONE if it is available then change it to your desired timezone. if it is not available then add it to your settings.py file. Please see an example given below. Save the settings.py file. TIME_ZONE = 'America/New_York' Hopefully, this answer will help you.",
            "keywords": "Python, knowledge, JavaScript, CSS, Algorithms, Tricks, Data Science, HTML, System Design, Android Development, django, Data Structures, Cybersecurity, Machine Learning, NodeJS, C++, React, Tutorial, C, Coding, Web Development, Technical Blogs, Programming, Cloud computing, Codeasify, Interview Questions, Interview Preparation, Technical blog, Computer Science, SQL"
        }
        ]